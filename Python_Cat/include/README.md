
### include/DataPreparation.py: 

This class, named `DataPreparation`, handles data preparation for training and evaluating classification models. Here is reported what it does specifically:
- _`load_data()` Function_ : This function loads data from the specified ROOT file using the `uproot` library. The file is opened, then signal and background trees are extracted. Data is loaded into two Pandas DataFrames: `df_signal` and `df_background`.
- _`prepare_data()` Function_: This function prepares data for training and evaluating classification models:
    - Firstly, relevant columns ('var1', 'var2', 'var3', 'var4', 'eta') are selected from both signal and background DataFrames. Subsequently, the data is normalized by dividing each variable by its maximum value (except 'eta', which is not normalized as categorization is intended; however, 'eta' could have been categorized with a threshold of 0.5 instead of 1.3, but this choice likely won't significantly affect training).
    - Normalized data is then concatenated into a single DataFrame `X`. A target vector `y` is also created, assigning label "1" to signal and "0" to background. Next, data is split into training and testing sets using the `train_test_split()` function from scikit-learn. The splitting is made assigning 80% of the dataset for training and 20% for test and the `random_state` parameter is set to 42 for reproducibility.
    - Finally, data is further divided into two groups based on the absolute value of the 'eta' variable, representing a physical property of the data. This allows creating two distinct categories of events to evaluate model performance on different eta ranges. Data and corresponding targets for these two categories are separated into `X_train_cat1`, `X_train_cat2`, `y_train_cat1`, and `y_train_cat2` for the training set, and `X_test_cat1`, `X_test_cat2`, `y_test_cat1`, and `y_test_cat2` for the testing set.
    - Finally, the `eta` columns are dropped to replicate what is done in the TMVA code. In practice, `eta` becomes a kind of spectator variable.

### include/Classifier.py nota: 
This code defines two classes: `SignalBackgroundClassifier` and `NeuralNetwork`, along with an auxiliary class named `Additional_evaluation`.
- **SignalBackgroundClassifier:**
    - This class handles the selection and training of classification models to distinguish signals and backgrounds. It is initialized with a specified model type (e.g., 'BDT', 'SVT', 'Neural_Network', 'Random_Forest', 'kNN') and training data split by categories.
    - The _`train_classifier()`_ method trains the classifier using training data and corresponding labels. It also calls methods of the `Additional_evaluation` class to visualize feature importance.
    - The _`evaluate_classifier()`_ method evaluates the model's performance using testing data and computes various metrics such as accuracy, ROC curve AUC, F1-score, and precision. It utilizes `classification_report(y_test, self.predictions))` to display the classification report (for both full dataset and categorisation). This report includes precision, f1-score, and recall for each class, along with the weighted average of these metrics.
    - In the case of the neural network (NN), the `SignalBackgroundClassifier` class handles the configuration and training of the NN similarly to other classifiers, but with some differences in the training and prediction process:
       - _Initialization:_ When a `SignalBackgroundClassifier` object with `model_type='Neural_Network'` is created, the class initializes a `NeuralNetwork` object and uses it as the classifier for the NN model.
       - _Training:_ During training, the `SignalBackgroundClassifier` class invokes the `train_classifier()` method from the `NeuralNetwork` object, providing it with the training data (`X_train`) and their corresponding labels (`y_train`). Inside the `train_classifier()` method, the `NeuralNetwork` class constructs and trains the neural network model utilizing the Keras API of TensorFlow. Conversely, for other models, only the `fit()` method is called.
       - _Prediction:_ in the SignalBackgroundClassifier class, predictions are made using the `predict()` method by comparing the probability threshold of 0.5, converting it to an integer using `.astype(int)`. Here, `probability = self.clf.model.predict(X_test)`. However, for other methods, predictions are determined solely by invoking the `predict()` method on `X_test`, while the probability is calculated separately using `predict_proba(X_test)[:, 1]`, which computes the predicted probability for the positive class (class 1).
- **NeuralNetwork:** This class represents a neural network (NN) model defined using the Keras API of TensorFlow.
    - The _`build_model()`_ method constructs the NN model specifying the network architecture and optimization parameters. The strucuture is defined as follows:
        - The input layer defines the shape of the network input, which is determined by the shape of the trained data.
        - The dense layers apply a linear transformation followed by a ReLu transformation function; the 'neurons' parameter defines the number of neurons in each layer and is determined by the grid search.
        - The dropout layers are introduced to reduce the likelihood of overfitting; they randomly deactivate some neurons at each iteration of training, so that each iteration relies on a different subset of neurons. In this way, the model is forced to learn the main features shared by the neurons and recursive patterns. The dropout parameter is again computed with the grid search.
        - The output layer is a dense layer with only one neuron: this is typical for binary classification problems.
        - The 'Adam' optimiser is chosen to update the weights during training; the learning rate parameter is obtained by grid search.
        - The model is compiled, specifying the optimiser, the loss function to be minimised, and the metric to be monitored during training (in this case, accuracy).
    - The _`train_classifier()`_ method trains the NN model using training data and corresponding labels; the training time is printed
- **Additional_evaluation:** This class contains auxiliary methods to further evaluate model performance.
    - The constructor accepts three parameters: `clf` (the trained classifier), `feature_names` (a list of feature names), and `model_type` (the type of classification model).    
    - The `plot_feature_importance(clf, X_test, y_test)` method visualizes the feature importance utilized by the classification model, but it is important to note that this is done only considering classifiers trained on the full dataset. If users wish, they can run this part of the code for categorization as well. Please refer to the note on how to do this. However, it's not executed here to avoid opening too many windows and causing confusion. Nonetheless, it remains an interesting tool to experiment with if desired.
         - For models like BDT and Random Forest, feature importance is computed during model training. This importance reflects how much each feature contributes to the overall predictive capability of the model. In the code, this importance is obtained from the `feature_importances_` attribute of the classifier (`clf`).
         - For SVM with a linear kernel, feature importance is calculated by examining the coefficients associated with the model. These coefficients represent the weights assigned to each feature in the model's decision-making process. In linear SVM, these weights are proportional to the importance of the features. The code extracts these coefficients (`coef_`) from the SVM classifier and computes the mean of the absolute values of the coefficients for each feature, representing their average importance.
         - For Neural Network models, feature importance is determined by the weights of the first layer of the neural network. These weights indicate the relative importance of features in model learning. The code calculates these weights as the mean of the absolute weight values for each feature in the first layer of the neural network. Subsequently, the mean feature importance values are sorted for visualization.
         - For kNN models, feature importance is derived by counting how often each feature appears among the nearest neighbors of instances in the test data. This count is normalized with respect to the total number of counts to obtain the relative importance of features. This method provides a measure of feature importance based on their frequency among the nearest neighbors of instances in the test data.



### include/MetricPrinter.py
The `PrintMetrics` class manages printing and visualization of model evaluation metrics. Here's what it does:
- _Initialization:_  During initialization, evaluation metrics to print and visualize are passed to the class constructor, such as the ROC curve (`fpr` and `tpr`), accuracy (`accuracy`), F1-score (`f1`), and precision (`precision`) for both the full dataset and the categories, and `y_test`, `y_test_combined`, `predictions`, `predictions_combined` for drawing the confusion matrix. These values are stored as object attributes. 
- _`plot_roc_curve()` Method:_ This method calculates background rejection as 1 - FPR and then plots signal efficiency against background rejection (a comparison among full dataset and categorisation). It uses `tpr` and `fpr` values for ROC curve plotting.
- _`print_metrics()` Method:_  This method is responsible for printing model evaluation metrics, including accuracy, F1-score, and precision, for both the full dataset and categorization. Additionally, it calculates a confusion matrix and displays for both the full dataset and categorization.
